{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvtUdN3Kw_vd",
        "outputId": "f24e60ca-7868-48ed-e95f-645419c47d1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TkCKcvCdxFmK",
        "outputId": "d053d4c7-1963-4ff2-a7c4-b8bd79158495"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting Autogluon\n",
            "  Downloading autogluon-0.8.2-py3-none-any.whl (9.7 kB)\n",
            "Collecting autogluon.core[all]==0.8.2 (from Autogluon)\n",
            "  Downloading autogluon.core-0.8.2-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.0/224.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting autogluon.features==0.8.2 (from Autogluon)\n",
            "  Downloading autogluon.features-0.8.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting autogluon.tabular[all]==0.8.2 (from Autogluon)\n",
            "  Downloading autogluon.tabular-0.8.2-py3-none-any.whl (285 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m285.7/285.7 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting autogluon.multimodal==0.8.2 (from Autogluon)\n",
            "  Downloading autogluon.multimodal-0.8.2-py3-none-any.whl (372 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m372.3/372.3 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting autogluon.timeseries[all]==0.8.2 (from Autogluon)\n",
            "  Downloading autogluon.timeseries-0.8.2-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<1.27,>=1.21 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.8.2->Autogluon) (1.23.5)\n",
            "Requirement already satisfied: scipy<1.12,>=1.5.4 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.8.2->Autogluon) (1.11.2)\n",
            "Requirement already satisfied: scikit-learn<1.3,>=1.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.8.2->Autogluon) (1.2.2)\n",
            "Requirement already satisfied: networkx<4,>=3.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.8.2->Autogluon) (3.1)\n",
            "Requirement already satisfied: pandas<1.6,>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.8.2->Autogluon) (1.5.3)\n",
            "Requirement already satisfied: tqdm<5,>=4.38 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.8.2->Autogluon) (4.66.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.8.2->Autogluon) (2.31.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.8.2->Autogluon) (3.7.1)\n",
            "Collecting boto3<2,>=1.10 (from autogluon.core[all]==0.8.2->Autogluon)\n",
            "  Downloading boto3-1.28.46-py3-none-any.whl (135 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.8/135.8 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting autogluon.common==0.8.2 (from autogluon.core[all]==0.8.2->Autogluon)\n",
            "  Downloading autogluon.common-0.8.2-py3-none-any.whl (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: hyperopt<0.2.8,>=0.2.7 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.8.2->Autogluon) (0.2.7)\n",
            "Collecting ray[default]<2.4,>=2.3 (from autogluon.core[all]==0.8.2->Autogluon)\n",
            "  Downloading ray-2.3.1-cp310-cp310-manylinux2014_x86_64.whl (58.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.5/58.5 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<2.0,>=1.10.4 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.8.2->Autogluon) (1.10.12)\n",
            "Collecting grpcio<=1.50.0,>=1.42.0 (from autogluon.core[all]==0.8.2->Autogluon)\n",
            "  Downloading grpcio-1.50.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m93.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Pillow<9.6,>=9.3 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.8.2->Autogluon) (9.4.0)\n",
            "Collecting jsonschema<4.18,>=4.14 (from autogluon.multimodal==0.8.2->Autogluon)\n",
            "  Downloading jsonschema-4.17.3-py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.4/90.4 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting seqeval<1.3.0,>=1.2.2 (from autogluon.multimodal==0.8.2->Autogluon)\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting evaluate<0.4.0,>=0.2.2 (from autogluon.multimodal==0.8.2->Autogluon)\n",
            "  Downloading evaluate-0.3.0-py3-none-any.whl (72 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate<0.17,>=0.9 (from autogluon.multimodal==0.8.2->Autogluon)\n",
            "  Downloading accelerate-0.16.0-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting timm<0.10.0,>=0.9.2 (from autogluon.multimodal==0.8.2->Autogluon)\n",
            "  Downloading timm-0.9.7-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m86.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch<1.14,>=1.9 (from autogluon.multimodal==0.8.2->Autogluon)\n",
            "  Downloading torch-1.13.1-cp310-cp310-manylinux1_x86_64.whl (887.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.5/887.5 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision<0.15.0 (from autogluon.multimodal==0.8.2->Autogluon)\n",
            "  Downloading torchvision-0.14.1-cp310-cp310-manylinux1_x86_64.whl (24.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.2/24.2 MB\u001b[0m \u001b[31m70.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-image<0.20.0,>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.8.2->Autogluon) (0.19.3)\n",
            "Collecting pytorch-lightning<1.10.0,>=1.9.0 (from autogluon.multimodal==0.8.2->Autogluon)\n",
            "  Downloading pytorch_lightning-1.9.5-py3-none-any.whl (829 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m829.5/829.5 kB\u001b[0m \u001b[31m67.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: text-unidecode<1.4,>=1.3 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.8.2->Autogluon) (1.3)\n",
            "Collecting torchmetrics<0.12.0,>=0.11.0 (from autogluon.multimodal==0.8.2->Autogluon)\n",
            "  Downloading torchmetrics-0.11.4-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.2/519.2 kB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers[sentencepiece]<4.27.0,>=4.23.0 (from autogluon.multimodal==0.8.2->Autogluon)\n",
            "  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m108.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nptyping<2.5.0,>=1.4.4 (from autogluon.multimodal==0.8.2->Autogluon)\n",
            "  Downloading nptyping-2.4.1-py3-none-any.whl (36 kB)\n",
            "Collecting omegaconf<2.3.0,>=2.1.1 (from autogluon.multimodal==0.8.2->Autogluon)\n",
            "  Downloading omegaconf-2.2.3-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.3/79.3 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytorch-metric-learning<2.0,>=1.3.0 (from autogluon.multimodal==0.8.2->Autogluon)\n",
            "  Downloading pytorch_metric_learning-1.7.3-py3-none-any.whl (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.2/112.2 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nlpaug<1.2.0,>=1.1.10 (from autogluon.multimodal==0.8.2->Autogluon)\n",
            "  Downloading nlpaug-1.1.11-py3-none-any.whl (410 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.5/410.5 kB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nltk<4.0.0,>=3.4.5 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.8.2->Autogluon) (3.8.1)\n",
            "Collecting openmim<0.4.0,>=0.3.7 (from autogluon.multimodal==0.8.2->Autogluon)\n",
            "  Downloading openmim-0.3.9-py2.py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: defusedxml<0.7.2,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.8.2->Autogluon) (0.7.1)\n",
            "Requirement already satisfied: jinja2<3.2,>=3.0.3 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.8.2->Autogluon) (3.1.2)\n",
            "Requirement already satisfied: tensorboard<3,>=2.9 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.8.2->Autogluon) (2.13.0)\n",
            "Collecting pytesseract<0.3.11,>=0.3.9 (from autogluon.multimodal==0.8.2->Autogluon)\n",
            "  Downloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
            "Collecting lightgbm<3.4,>=3.3 (from autogluon.tabular[all]==0.8.2->Autogluon)\n",
            "  Downloading lightgbm-3.3.5-py3-none-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m88.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: xgboost<1.8,>=1.6 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular[all]==0.8.2->Autogluon) (1.7.6)\n",
            "Requirement already satisfied: fastai<2.8,>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular[all]==0.8.2->Autogluon) (2.7.12)\n",
            "Collecting catboost<1.3,>=1.1 (from autogluon.tabular[all]==0.8.2->Autogluon)\n",
            "  Downloading catboost-1.2.1-cp310-cp310-manylinux2014_x86_64.whl (98.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib<2,>=1.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.timeseries[all]==0.8.2->Autogluon) (1.3.2)\n",
            "Requirement already satisfied: statsmodels<0.15,>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.timeseries[all]==0.8.2->Autogluon) (0.14.0)\n",
            "Collecting gluonts<0.14,>=0.13.1 (from autogluon.timeseries[all]==0.8.2->Autogluon)\n",
            "  Downloading gluonts-0.13.4-py3-none-any.whl (812 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m812.1/812.1 kB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting statsforecast<1.5,>=1.4.0 (from autogluon.timeseries[all]==0.8.2->Autogluon)\n",
            "  Downloading statsforecast-1.4.0-py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mlforecast<0.7.4,>=0.7.0 (from autogluon.timeseries[all]==0.8.2->Autogluon)\n",
            "  Downloading mlforecast-0.7.3-py3-none-any.whl (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ujson<6,>=5 (from autogluon.timeseries[all]==0.8.2->Autogluon)\n",
            "  Downloading ujson-5.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.9/53.9 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil<6,>=5.7.3 in /usr/local/lib/python3.10/dist-packages (from autogluon.common==0.8.2->autogluon.core[all]==0.8.2->Autogluon) (5.9.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from autogluon.common==0.8.2->autogluon.core[all]==0.8.2->Autogluon) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate<0.17,>=0.9->autogluon.multimodal==0.8.2->Autogluon) (23.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate<0.17,>=0.9->autogluon.multimodal==0.8.2->Autogluon) (6.0.1)\n",
            "Collecting botocore<1.32.0,>=1.31.46 (from boto3<2,>=1.10->autogluon.core[all]==0.8.2->Autogluon)\n",
            "  Downloading botocore-1.31.46-py3-none-any.whl (11.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.2/11.2 MB\u001b[0m \u001b[31m113.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3<2,>=1.10->autogluon.core[all]==0.8.2->Autogluon)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.7.0,>=0.6.0 (from boto3<2,>=1.10->autogluon.core[all]==0.8.2->Autogluon)\n",
            "  Downloading s3transfer-0.6.2-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost<1.3,>=1.1->autogluon.tabular[all]==0.8.2->Autogluon) (0.20.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost<1.3,>=1.1->autogluon.tabular[all]==0.8.2->Autogluon) (5.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost<1.3,>=1.1->autogluon.tabular[all]==0.8.2->Autogluon) (1.16.0)\n",
            "Collecting datasets>=2.0.0 (from evaluate<0.4.0,>=0.2.2->autogluon.multimodal==0.8.2->Autogluon)\n",
            "  Downloading datasets-2.14.5-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.6/519.6 kB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dill (from evaluate<0.4.0,>=0.2.2->autogluon.multimodal==0.8.2->Autogluon)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xxhash (from evaluate<0.4.0,>=0.2.2->autogluon.multimodal==0.8.2->Autogluon)\n",
            "  Downloading xxhash-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from evaluate<0.4.0,>=0.2.2->autogluon.multimodal==0.8.2->Autogluon)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate<0.4.0,>=0.2.2->autogluon.multimodal==0.8.2->Autogluon) (2023.6.0)\n",
            "Collecting huggingface-hub>=0.7.0 (from evaluate<0.4.0,>=0.2.2->autogluon.multimodal==0.8.2->Autogluon)\n",
            "  Downloading huggingface_hub-0.17.1-py3-none-any.whl (294 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.8/294.8 kB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting responses<0.19 (from evaluate<0.4.0,>=0.2.2->autogluon.multimodal==0.8.2->Autogluon)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.8.2->Autogluon) (23.1.2)\n",
            "Requirement already satisfied: fastdownload<2,>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.8.2->Autogluon) (0.0.7)\n",
            "Requirement already satisfied: fastcore<1.6,>=1.5.29 in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.8.2->Autogluon) (1.5.29)\n",
            "Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.8.2->Autogluon) (1.0.3)\n",
            "Requirement already satisfied: spacy<4 in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.8.2->Autogluon) (3.6.1)\n",
            "Requirement already satisfied: toolz~=0.10 in /usr/local/lib/python3.10/dist-packages (from gluonts<0.14,>=0.13.1->autogluon.timeseries[all]==0.8.2->Autogluon) (0.12.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gluonts<0.14,>=0.13.1->autogluon.timeseries[all]==0.8.2->Autogluon) (4.5.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==0.8.2->Autogluon) (0.18.3)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==0.8.2->Autogluon) (2.2.1)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==0.8.2->Autogluon) (0.10.9.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2<3.2,>=3.0.3->autogluon.multimodal==0.8.2->Autogluon) (2.1.3)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema<4.18,>=4.14->autogluon.multimodal==0.8.2->Autogluon) (23.1.0)\n",
            "Collecting pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 (from jsonschema<4.18,>=4.14->autogluon.multimodal==0.8.2->Autogluon)\n",
            "  Downloading pyrsistent-0.19.3-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from lightgbm<3.4,>=3.3->autogluon.tabular[all]==0.8.2->Autogluon) (0.41.2)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from mlforecast<0.7.4,>=0.7.0->autogluon.timeseries[all]==0.8.2->Autogluon) (0.56.4)\n",
            "Collecting window-ops (from mlforecast<0.7.4,>=0.7.0->autogluon.timeseries[all]==0.8.2->Autogluon)\n",
            "  Downloading window_ops-0.0.14-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: gdown>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==0.8.2->Autogluon) (4.6.6)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.4.5->autogluon.multimodal==0.8.2->Autogluon) (8.1.7)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.4.5->autogluon.multimodal==0.8.2->Autogluon) (2023.6.3)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from omegaconf<2.3.0,>=2.1.1->autogluon.multimodal==0.8.2->Autogluon)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting colorama (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==0.8.2->Autogluon)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting model-index (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==0.8.2->Autogluon)\n",
            "  Downloading model_index-0.1.11-py3-none-any.whl (34 kB)\n",
            "Collecting opendatalab (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==0.8.2->Autogluon)\n",
            "  Downloading opendatalab-0.0.10-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==0.8.2->Autogluon) (13.5.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==0.8.2->Autogluon) (0.9.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas<1.6,>=1.4.1->autogluon.core[all]==0.8.2->Autogluon) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<1.6,>=1.4.1->autogluon.core[all]==0.8.2->Autogluon) (2023.3.post1)\n",
            "Collecting lightning-utilities>=0.6.0.post0 (from pytorch-lightning<1.10.0,>=1.9.0->autogluon.multimodal==0.8.2->Autogluon)\n",
            "  Downloading lightning_utilities-0.9.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from ray[default]<2.4,>=2.3->autogluon.core[all]==0.8.2->Autogluon) (3.12.2)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray[default]<2.4,>=2.3->autogluon.core[all]==0.8.2->Autogluon) (1.0.5)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.10/dist-packages (from ray[default]<2.4,>=2.3->autogluon.core[all]==0.8.2->Autogluon) (3.20.3)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray[default]<2.4,>=2.3->autogluon.core[all]==0.8.2->Autogluon) (1.3.1)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray[default]<2.4,>=2.3->autogluon.core[all]==0.8.2->Autogluon) (1.4.0)\n",
            "Collecting virtualenv>=20.0.24 (from ray[default]<2.4,>=2.3->autogluon.core[all]==0.8.2->Autogluon)\n",
            "  Downloading virtualenv-20.24.5-py3-none-any.whl (3.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m103.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp>=3.7 in /usr/local/lib/python3.10/dist-packages (from ray[default]<2.4,>=2.3->autogluon.core[all]==0.8.2->Autogluon) (3.8.5)\n",
            "Collecting aiohttp-cors (from ray[default]<2.4,>=2.3->autogluon.core[all]==0.8.2->Autogluon)\n",
            "  Downloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\n",
            "Collecting colorful (from ray[default]<2.4,>=2.3->autogluon.core[all]==0.8.2->Autogluon)\n",
            "  Downloading colorful-0.5.5-py2.py3-none-any.whl (201 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.4/201.4 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting py-spy>=0.2.0 (from ray[default]<2.4,>=2.3->autogluon.core[all]==0.8.2->Autogluon)\n",
            "  Downloading py_spy-0.3.14-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m83.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gpustat>=1.0.0 (from ray[default]<2.4,>=2.3->autogluon.core[all]==0.8.2->Autogluon)\n",
            "  Downloading gpustat-1.1.1.tar.gz (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.1/98.1 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting opencensus (from ray[default]<2.4,>=2.3->autogluon.core[all]==0.8.2->Autogluon)\n",
            "  Downloading opencensus-0.11.2-py2.py3-none-any.whl (128 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: prometheus-client>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from ray[default]<2.4,>=2.3->autogluon.core[all]==0.8.2->Autogluon) (0.17.1)\n",
            "Requirement already satisfied: smart-open in /usr/local/lib/python3.10/dist-packages (from ray[default]<2.4,>=2.3->autogluon.core[all]==0.8.2->Autogluon) (6.4.0)\n",
            "Collecting tensorboardX>=1.9 (from ray[default]<2.4,>=2.3->autogluon.core[all]==0.8.2->Autogluon)\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->autogluon.core[all]==0.8.2->Autogluon) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->autogluon.core[all]==0.8.2->Autogluon) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->autogluon.core[all]==0.8.2->Autogluon) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->autogluon.core[all]==0.8.2->Autogluon) (2023.7.22)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image<0.20.0,>=0.19.1->autogluon.multimodal==0.8.2->Autogluon) (2.31.3)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image<0.20.0,>=0.19.1->autogluon.multimodal==0.8.2->Autogluon) (2023.8.30)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image<0.20.0,>=0.19.1->autogluon.multimodal==0.8.2->Autogluon) (1.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<1.3,>=1.0->autogluon.core[all]==0.8.2->Autogluon) (3.2.0)\n",
            "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from statsmodels<0.15,>=0.13.0->autogluon.timeseries[all]==0.8.2->Autogluon) (0.5.3)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==0.8.2->Autogluon) (1.4.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==0.8.2->Autogluon) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==0.8.2->Autogluon) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==0.8.2->Autogluon) (3.4.4)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==0.8.2->Autogluon) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==0.8.2->Autogluon) (2.3.7)\n",
            "Collecting safetensors (from timm<0.10.0,>=0.9.2->autogluon.multimodal==0.8.2->Autogluon)\n",
            "  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m78.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99 (from torch<1.14,>=1.9->autogluon.multimodal==0.8.2->Autogluon)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m64.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch<1.14,>=1.9->autogluon.multimodal==0.8.2->Autogluon)\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from torch<1.14,>=1.9->autogluon.multimodal==0.8.2->Autogluon)\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch<1.14,>=1.9->autogluon.multimodal==0.8.2->Autogluon)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m84.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers[sentencepiece]<4.27.0,>=4.23.0->autogluon.multimodal==0.8.2->Autogluon)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m116.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece!=0.1.92,>=0.1.91 (from transformers[sentencepiece]<4.27.0,>=4.23.0->autogluon.multimodal==0.8.2->Autogluon)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m71.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting protobuf!=3.19.5,>=3.15.3 (from ray[default]<2.4,>=2.3->autogluon.core[all]==0.8.2->Autogluon)\n",
            "  Downloading protobuf-3.20.2-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m67.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core[all]==0.8.2->Autogluon) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core[all]==0.8.2->Autogluon) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core[all]==0.8.2->Autogluon) (4.42.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core[all]==0.8.2->Autogluon) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core[all]==0.8.2->Autogluon) (3.1.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7->ray[default]<2.4,>=2.3->autogluon.core[all]==0.8.2->Autogluon) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7->ray[default]<2.4,>=2.3->autogluon.core[all]==0.8.2->Autogluon) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7->ray[default]<2.4,>=2.3->autogluon.core[all]==0.8.2->Autogluon) (1.9.2)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests->autogluon.core[all]==0.8.2->Autogluon)\n",
            "  Downloading urllib3-1.26.16-py2.py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.1/143.1 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate<0.4.0,>=0.2.2->autogluon.multimodal==0.8.2->Autogluon) (9.0.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==0.8.2->Autogluon) (4.11.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.9->autogluon.multimodal==0.8.2->Autogluon) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.9->autogluon.multimodal==0.8.2->Autogluon) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.9->autogluon.multimodal==0.8.2->Autogluon) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<3,>=2.9->autogluon.multimodal==0.8.2->Autogluon) (1.3.1)\n",
            "Collecting nvidia-ml-py>=11.450.129 (from gpustat>=1.0.0->ray[default]<2.4,>=2.3->autogluon.core[all]==0.8.2->Autogluon)\n",
            "  Downloading nvidia_ml_py-12.535.108-py3-none-any.whl (36 kB)\n",
            "Collecting blessed>=1.17.1 (from gpustat>=1.0.0->ray[default]<2.4,>=2.3->autogluon.core[all]==0.8.2->Autogluon)\n",
            "  Downloading blessed-1.20.0-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->mlforecast<0.7.4,>=0.7.0->autogluon.timeseries[all]==0.8.2->Autogluon) (0.39.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.8.2->Autogluon) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.8.2->Autogluon) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.8.2->Autogluon) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.8.2->Autogluon) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.8.2->Autogluon) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.8.2->Autogluon) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.8.2->Autogluon) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.8.2->Autogluon) (2.4.7)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.8.2->Autogluon) (2.0.9)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.8.2->Autogluon) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.8.2->Autogluon) (0.10.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.8.2->Autogluon) (3.3.0)\n",
            "Collecting distlib<1,>=0.3.7 (from virtualenv>=20.0.24->ray[default]<2.4,>=2.3->autogluon.core[all]==0.8.2->Autogluon)\n",
            "  Downloading distlib-0.3.7-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.9/468.9 kB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: platformdirs<4,>=3.9.1 in /usr/local/lib/python3.10/dist-packages (from virtualenv>=20.0.24->ray[default]<2.4,>=2.3->autogluon.core[all]==0.8.2->Autogluon) (3.10.0)\n",
            "Collecting ordered-set (from model-index->openmim<0.4.0,>=0.3.7->autogluon.multimodal==0.8.2->Autogluon)\n",
            "  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
            "Collecting opencensus-context>=0.1.3 (from opencensus->ray[default]<2.4,>=2.3->autogluon.core[all]==0.8.2->Autogluon)\n",
            "  Downloading opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opencensus->ray[default]<2.4,>=2.3->autogluon.core[all]==0.8.2->Autogluon) (2.11.1)\n",
            "Collecting pycryptodome (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==0.8.2->Autogluon)\n",
            "  Downloading pycryptodome-3.18.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m89.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openxlab (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==0.8.2->Autogluon)\n",
            "  Downloading openxlab-0.0.24-py3-none-any.whl (291 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m291.2/291.2 kB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost<1.3,>=1.1->autogluon.tabular[all]==0.8.2->Autogluon) (8.2.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==0.8.2->Autogluon) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==0.8.2->Autogluon) (2.16.1)\n",
            "Requirement already satisfied: wcwidth>=0.1.4 in /usr/local/lib/python3.10/dist-packages (from blessed>=1.17.1->gpustat>=1.0.0->ray[default]<2.4,>=2.3->autogluon.core[all]==0.8.2->Autogluon) (0.2.6)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]<2.4,>=2.3->autogluon.core[all]==0.8.2->Autogluon) (1.60.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==0.8.2->Autogluon) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<3,>=2.9->autogluon.multimodal==0.8.2->Autogluon) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<3,>=2.9->autogluon.multimodal==0.8.2->Autogluon) (3.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.8.2->Autogluon) (0.7.10)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.8.2->Autogluon) (0.1.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==0.8.2->Autogluon) (2.5)\n",
            "Collecting oss2~=2.17.0 (from openxlab->opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==0.8.2->Autogluon)\n",
            "  Downloading oss2-2.17.0.tar.gz (259 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.5/259.5 kB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting requests (from autogluon.core[all]==0.8.2->Autogluon)\n",
            "  Downloading requests-2.28.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rich (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==0.8.2->Autogluon)\n",
            "  Downloading rich-13.4.2-py3-none-any.whl (239 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.4/239.4 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting setuptools (from autogluon.common==0.8.2->autogluon.core[all]==0.8.2->Autogluon)\n",
            "  Downloading setuptools-60.2.0-py3-none-any.whl (953 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.1/953.1 kB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tqdm<5,>=4.38 (from autogluon.core[all]==0.8.2->Autogluon)\n",
            "  Downloading tqdm-4.65.2-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of requests[socks] to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting requests[socks] (from gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==0.8.2->Autogluon)\n",
            "  Downloading requests-2.30.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading requests-2.29.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests->autogluon.core[all]==0.8.2->Autogluon) (1.7.1)\n",
            "Collecting crcmod>=1.7 (from oss2~=2.17.0->openxlab->opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==0.8.2->Autogluon)\n",
            "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting aliyun-python-sdk-kms>=2.4.1 (from oss2~=2.17.0->openxlab->opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==0.8.2->Autogluon)\n",
            "  Downloading aliyun_python_sdk_kms-2.16.2-py2.py3-none-any.whl (94 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.0/94.0 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aliyun-python-sdk-core>=2.13.12 (from oss2~=2.17.0->openxlab->opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==0.8.2->Autogluon)\n",
            "  Downloading aliyun-python-sdk-core-2.13.36.tar.gz (440 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.5/440.5 kB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3<2,>=1.10->autogluon.core[all]==0.8.2->Autogluon)\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: cryptography>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==0.8.2->Autogluon) (41.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=2.6.0->aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==0.8.2->Autogluon) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=2.6.0->aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==0.8.2->Autogluon) (2.21)\n",
            "Building wheels for collected packages: antlr4-python3-runtime, seqeval, gpustat, oss2, aliyun-python-sdk-core, crcmod\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=73b43e5949345eb21e8644a01d0dcd2d6bc50195200ef10991f70eb24335ba22\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=7f8a856ee9498ab4f9d843a228d6470822b0cef2a8ef38de7abefda934fbb294\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
            "  Building wheel for gpustat (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gpustat: filename=gpustat-1.1.1-py3-none-any.whl size=26411 sha256=853a8a5b2a34974aa5faba1b6055ddc1f872858b33fc026f963d7b527c08d838\n",
            "  Stored in directory: /root/.cache/pip/wheels/ec/d7/80/a71ba3540900e1f276bcae685efd8e590c810d2108b95f1e47\n",
            "  Building wheel for oss2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for oss2: filename=oss2-2.17.0-py3-none-any.whl size=112371 sha256=c2cb7f4271a06204393973cf8ea7251aec32da77b869e3aa0b1ccb48f830381b\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/04/7b/7e61b8157fdf211c5131375240d0d86ca82e2a88ead9672c88\n",
            "  Building wheel for aliyun-python-sdk-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for aliyun-python-sdk-core: filename=aliyun_python_sdk_core-2.13.36-py3-none-any.whl size=533190 sha256=fec4a4ec52069cf9a00e0965f977f696e465387d4fba3ecdf54ff32691f17d04\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/f4/0e/87c534857132bd3bd2c4465c0b15b4db650cf6c15a876bda34\n",
            "  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for crcmod: filename=crcmod-1.7-cp310-cp310-linux_x86_64.whl size=31410 sha256=16c8205057ba71cf61424c9ed41390983031c55cba494812a0e16e3a74c4490b\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/4c/07/72215c529bd59d67e3dac29711d7aba1b692f543c808ba9e86\n",
            "Successfully built antlr4-python3-runtime seqeval gpustat oss2 aliyun-python-sdk-core crcmod\n",
            "Installing collected packages: tokenizers, sentencepiece, safetensors, py-spy, opencensus-context, nvidia-ml-py, distlib, crcmod, colorful, antlr4-python3-runtime, xxhash, virtualenv, urllib3, ujson, tqdm, setuptools, pytesseract, pyrsistent, pycryptodome, protobuf, ordered-set, omegaconf, nvidia-cuda-nvrtc-cu11, nptyping, lightning-utilities, jmespath, grpcio, dill, colorama, blessed, tensorboardX, rich, requests, nvidia-cuda-runtime-cu11, nvidia-cublas-cu11, multiprocess, model-index, jsonschema, gpustat, botocore, window-ops, seqeval, s3transfer, responses, ray, nvidia-cudnn-cu11, lightgbm, huggingface-hub, gluonts, catboost, aliyun-python-sdk-core, aiohttp-cors, transformers, torch, statsforecast, opencensus, mlforecast, datasets, boto3, aliyun-python-sdk-kms, torchvision, torchmetrics, pytorch-metric-learning, oss2, nlpaug, evaluate, autogluon.common, accelerate, timm, pytorch-lightning, openxlab, autogluon.features, autogluon.core, opendatalab, autogluon.tabular, openmim, autogluon.timeseries, autogluon.multimodal, Autogluon\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.0.4\n",
            "    Uninstalling urllib3-2.0.4:\n",
            "      Successfully uninstalled urllib3-2.0.4\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.66.1\n",
            "    Uninstalling tqdm-4.66.1:\n",
            "      Successfully uninstalled tqdm-4.66.1\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 67.7.2\n",
            "    Uninstalling setuptools-67.7.2:\n",
            "      Successfully uninstalled setuptools-67.7.2\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.57.0\n",
            "    Uninstalling grpcio-1.57.0:\n",
            "      Successfully uninstalled grpcio-1.57.0\n",
            "  Attempting uninstall: rich\n",
            "    Found existing installation: rich 13.5.2\n",
            "    Uninstalling rich-13.5.2:\n",
            "      Successfully uninstalled rich-13.5.2\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.31.0\n",
            "    Uninstalling requests-2.31.0:\n",
            "      Successfully uninstalled requests-2.31.0\n",
            "  Attempting uninstall: jsonschema\n",
            "    Found existing installation: jsonschema 4.19.0\n",
            "    Uninstalling jsonschema-4.19.0:\n",
            "      Successfully uninstalled jsonschema-4.19.0\n",
            "  Attempting uninstall: lightgbm\n",
            "    Found existing installation: lightgbm 4.0.0\n",
            "    Uninstalling lightgbm-4.0.0:\n",
            "      Successfully uninstalled lightgbm-4.0.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.0.1+cu118\n",
            "    Uninstalling torch-2.0.1+cu118:\n",
            "      Successfully uninstalled torch-2.0.1+cu118\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.15.2+cu118\n",
            "    Uninstalling torchvision-0.15.2+cu118:\n",
            "      Successfully uninstalled torchvision-0.15.2+cu118\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "cvxpy 1.3.2 requires setuptools>65.5.1, but you have setuptools 60.2.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.28.2 which is incompatible.\n",
            "tensorflow 2.13.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 3.20.2 which is incompatible.\n",
            "tensorflow-metadata 1.14.0 requires protobuf<4.21,>=3.20.3, but you have protobuf 3.20.2 which is incompatible.\n",
            "torchaudio 2.0.2+cu118 requires torch==2.0.1, but you have torch 1.13.1 which is incompatible.\n",
            "torchdata 0.6.1 requires torch==2.0.1, but you have torch 1.13.1 which is incompatible.\n",
            "torchtext 0.15.2 requires torch==2.0.1, but you have torch 1.13.1 which is incompatible.\n",
            "yfinance 0.2.28 requires requests>=2.31, but you have requests 2.28.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Autogluon-0.8.2 accelerate-0.16.0 aiohttp-cors-0.7.0 aliyun-python-sdk-core-2.13.36 aliyun-python-sdk-kms-2.16.2 antlr4-python3-runtime-4.9.3 autogluon.common-0.8.2 autogluon.core-0.8.2 autogluon.features-0.8.2 autogluon.multimodal-0.8.2 autogluon.tabular-0.8.2 autogluon.timeseries-0.8.2 blessed-1.20.0 boto3-1.28.46 botocore-1.31.46 catboost-1.2.1 colorama-0.4.6 colorful-0.5.5 crcmod-1.7 datasets-2.14.5 dill-0.3.7 distlib-0.3.7 evaluate-0.3.0 gluonts-0.13.4 gpustat-1.1.1 grpcio-1.50.0 huggingface-hub-0.17.1 jmespath-0.10.0 jsonschema-4.17.3 lightgbm-3.3.5 lightning-utilities-0.9.0 mlforecast-0.7.3 model-index-0.1.11 multiprocess-0.70.15 nlpaug-1.1.11 nptyping-2.4.1 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-ml-py-12.535.108 omegaconf-2.2.3 opencensus-0.11.2 opencensus-context-0.1.3 opendatalab-0.0.10 openmim-0.3.9 openxlab-0.0.24 ordered-set-4.1.0 oss2-2.17.0 protobuf-3.20.2 py-spy-0.3.14 pycryptodome-3.18.0 pyrsistent-0.19.3 pytesseract-0.3.10 pytorch-lightning-1.9.5 pytorch-metric-learning-1.7.3 ray-2.3.1 requests-2.28.2 responses-0.18.0 rich-13.4.2 s3transfer-0.6.2 safetensors-0.3.3 sentencepiece-0.1.99 seqeval-1.2.2 setuptools-60.2.0 statsforecast-1.4.0 tensorboardX-2.6.2.2 timm-0.9.7 tokenizers-0.13.3 torch-1.13.1 torchmetrics-0.11.4 torchvision-0.14.1 tqdm-4.65.2 transformers-4.26.1 ujson-5.8.0 urllib3-1.26.16 virtualenv-20.24.5 window-ops-0.0.14 xxhash-3.3.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack",
                  "google",
                  "pkg_resources",
                  "pydevd_plugins",
                  "setuptools"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting rdkit\n",
            "  Downloading rdkit-2023.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.7/29.7 MB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rdkit) (1.23.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit) (9.4.0)\n",
            "Installing collected packages: rdkit\n",
            "Successfully installed rdkit-2023.3.3\n"
          ]
        }
      ],
      "source": [
        "!pip install Autogluon\n",
        "!pip install rdkit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kvY2HmDexFj3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ineeji\\anaconda3\\envs\\Ag\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from tqdm import tqdm\n",
        "import math\n",
        "import os\n",
        "import torch\n",
        "import random\n",
        "\n",
        "from autogluon.tabular import TabularDataset, TabularPredictor\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_validate, train_test_split\n",
        "import itertools\n",
        "import math\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "EOkxYa8YQHrK"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import datasets, ensemble\n",
        "from catboost import CatBoostRegressor\n",
        "from tqdm import tqdm\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import make_scorer, mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem, PandasTools\n",
        "from rdkit import DataStructs\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "J5ABvxqhQGsI"
      },
      "outputs": [],
      "source": [
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem\n",
        "from rdkit.Chem.Draw import IPythonConsole\n",
        "from rdkit.Chem import Draw\n",
        "from rdkit.Chem.Draw.MolDrawing import MolDrawing, DrawingOptions\n",
        "from rdkit.Chem import Descriptors\n",
        "DrawingOptions.bondLineWidth=1.8\n",
        "from rdkit.Chem.rdmolops import SanitizeFlags\n",
        "\n",
        "# https://github.com/jensengroup/xyz2mol\n",
        "# from xyz2mol import xyz2mol\n",
        "from pathlib import Path\n",
        "import pickle\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7v38YrfjxFhn"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime as dt\n",
        "from tqdm.auto import tqdm\n",
        "# from sklearn.preprocessing import LabelEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "import gc\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "path = '/content/drive/MyDrive/DACON/bio/new/'\n",
        "\n",
        "train = pd.read_csv('train_clean.csv')\n",
        "test = pd.read_csv('test_clean.csv')\n",
        "submission = pd.read_csv('sample_submission.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_nVb_x21xO3x"
      },
      "outputs": [],
      "source": [
        "duplicates = train[train.duplicated(subset='SMILES', keep=False)]\n",
        "smiles_duplicate = duplicates['SMILES'].unique()\n",
        "\n",
        "for i in smiles_duplicate:\n",
        "    train.reset_index(drop=True, inplace=True)\n",
        "    df = train[train['SMILES']==i]\n",
        "    index_list = df.index\n",
        "    mlm_mean, hlm_mean = np.mean(df['MLM']), np.mean(df['HLM'])\n",
        "    train = train.drop(index_list[1:])\n",
        "    train.loc[index_list[0], 'MLM'] = mlm_mean\n",
        "    train.loc[index_list[0], 'HLM'] = hlm_mean\n",
        "\n",
        "train.reset_index(drop=True, inplace=True)\n",
        "test.reset_index(drop=True, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTQDjAu6DKex"
      },
      "source": [
        "# AllChem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "sLlXBzjIieXx"
      },
      "outputs": [],
      "source": [
        "def generate_fingerprint(smiles_string):\n",
        "    mol = Chem.MolFromSmiles(smiles_string)\n",
        "    if mol is not None:\n",
        "        fingerprint = AllChem.GetMorganFingerprintAsBitVect(mol, 2, nBits=2048)\n",
        "        return list(fingerprint)\n",
        "    else:\n",
        "        return [0]*2048\n",
        "\n",
        "def mol2fp(mol):\n",
        "    fp = AllChem.GetHashedMorganFingerprint(mol, 6, nBits=4096)\n",
        "    ar = np.zeros((1,), dtype=np.int8)\n",
        "    DataStructs.ConvertToNumpyArray(fp, ar)\n",
        "    return ar\n",
        "\n",
        "def number_of_atoms(atom_list, df):\n",
        "    for i in atom_list:\n",
        "        df['num_of_{}_atoms'.format(i)] = df['mol'].apply(lambda x: len(x.GetSubstructMatches(Chem.MolFromSmiles(i))))\n",
        "\n",
        "def data_processing(df):\n",
        "    df_fingerprint = df['SMILES'].apply(generate_fingerprint)\n",
        "    df_fingerprint = pd.DataFrame(df_fingerprint.tolist(), columns=[f'bit_{i}' for i in range(2048)])\n",
        "    df = pd.concat([df.drop(columns=['id']), df_fingerprint], axis=1)\n",
        "\n",
        "    PandasTools.AddMoleculeColumnToFrame(df,'SMILES','Molecule')\n",
        "    df[\"FPs\"] = df.Molecule.apply(mol2fp)\n",
        "\n",
        "    df['mol'] = df['SMILES'].apply(lambda x: Chem.MolFromSmiles(x))\n",
        "    df['mol'] = df['mol'].apply(lambda x: Chem.AddHs(x))\n",
        "    df['num_of_atoms'] = df['mol'].apply(lambda x: x.GetNumAtoms())\n",
        "    df['num_of_heavy_atoms'] = df['mol'].apply(lambda x: x.GetNumHeavyAtoms())\n",
        "    df['tpsa'] = df['mol'].apply(lambda x: Descriptors.TPSA(x))\n",
        "    df['mol_w'] = df['mol'].apply(lambda x: Descriptors.ExactMolWt(x))\n",
        "    df['num_valence_electrons'] = df['mol'].apply(lambda x: Descriptors.NumValenceElectrons(x))\n",
        "    df['num_heteroatoms'] = df['mol'].apply(lambda x: Descriptors.NumHeteroatoms(x))\n",
        "\n",
        "    number_of_atoms(['C','O', 'N', 'Cl'], df)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "from rdkit.Chem import PandasTools\n",
        "from rdkit import DataStructs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "s_Box4mal1pZ"
      },
      "outputs": [],
      "source": [
        "train = data_processing(train)\n",
        "test = data_processing(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "61f_oyeAxOzO"
      },
      "outputs": [],
      "source": [
        "train_mlm = train.drop(columns=['HLM'])\n",
        "train_hlm = train.drop(columns=['MLM'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "GcgLnXGnxOw6"
      },
      "outputs": [],
      "source": [
        "object_columns = train_mlm.select_dtypes(include=['object']).columns\n",
        "train_mlm = train_mlm.drop(columns=object_columns)\n",
        "\n",
        "object_columns = train_hlm.select_dtypes(include=['object']).columns\n",
        "train_hlm = train_hlm.drop(columns=object_columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxyhd_vOxFfO",
        "outputId": "441c6b30-e7b3-4b83-c15e-b1b64cacbb58"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels\\ag-20230913_040522\\\"\n",
            "Presets specified: ['best_quality']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
            "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (3471 samples, 92.0 MB).\n",
            "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels\\ag-20230913_040522\\\"\n",
            "AutoGluon Version:  0.8.2\n",
            "Python Version:     3.10.12\n",
            "Operating System:   Windows\n",
            "Platform Machine:   AMD64\n",
            "Platform Version:   10.0.22621\n",
            "Disk Space Avail:   42.47 GB / 511.09 GB (8.3%)\n",
            "Train Data Rows:    3471\n",
            "Train Data Columns: 3314\n",
            "Label Column: MLM\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (131.72, 0.0, 37.39137, 35.65765)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    14821.05 MB\n",
            "\tTrain Data (Original)  Memory Usage: 91.97 MB (0.6% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 2097 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tUseless Original Features (Count: 139): ['nB', 'nP', 'NsLi', 'NssBe', 'NssssBe', 'NssBH', 'NsssB', 'NssssB', 'NtCH', 'NddC', 'NsNH3', 'NssNH2', 'NsssNH', 'NsSiH3', 'NssSiH2', 'NsssSiH', 'NssssSi', 'NsPH2', 'NssPH', 'NsssP', 'NdsssP', 'NsssssP', 'NsSH', 'NsGeH3', 'NssGeH2', 'NsssGeH', 'NssssGe', 'NsAsH2', 'NssAsH', 'NsssAs', 'NsssdAs', 'NsssssAs', 'NsSeH', 'NdSe', 'NssSe', 'NdssSe', 'NddssSe', 'NsSnH3', 'NssSnH2', 'NsssSnH', 'NssssSn', 'NsPbH3', 'NssPbH2', 'NsssPbH', 'NssssPb', 'SsLi', 'SssBe', 'SssssBe', 'SssBH', 'SsssB', 'SssssB', 'StCH', 'SddC', 'SsNH3', 'SssNH2', 'SsssNH', 'SsSiH3', 'SssSiH2', 'SsssSiH', 'SssssSi', 'SsPH2', 'SssPH', 'SsssP', 'SdsssP', 'SsssssP', 'SsSH', 'SsGeH3', 'SssGeH2', 'SsssGeH', 'SssssGe', 'SsAsH2', 'SssAsH', 'SsssAs', 'SsssdAs', 'SsssssAs', 'SsSeH', 'SdSe', 'SssSe', 'SdssSe', 'SddssSe', 'SsSnH3', 'SssSnH2', 'SsssSnH', 'SssssSn', 'SsPbH3', 'SssPbH2', 'SsssPbH', 'SssssPb', 'SMR_VSA8', 'SlogP_VSA9', 'n9Ring', 'n10Ring', 'n12Ring', 'n8HRing', 'n9HRing', 'n10HRing', 'n12HRing', 'n3aRing', 'n4aRing', 'n8aRing', 'n9aRing', 'n10aRing', 'n11aRing', 'n12aRing', 'nG12aRing', 'n3aHRing', 'n4aHRing', 'n7aHRing', 'n8aHRing', 'n9aHRing', 'n10aHRing', 'n11aHRing', 'n12aHRing', 'nG12aHRing', 'n9ARing', 'n10ARing', 'n12ARing', 'n8AHRing', 'n9AHRing', 'n10AHRing', 'n12AHRing', 'n4FRing', 'n5FRing', 'n4FHRing', 'n5FHRing', 'n4FaRing', 'n5FaRing', 'n6FaRing', 'n7FaRing', 'n11FaRing', 'n4FaHRing', 'n5FaHRing', 'n6FaHRing', 'n7FaHRing', 'n11FaHRing', 'n4FARing', 'n5FARing', 'n4FAHRing', 'n5FAHRing']\n",
            "\t\tThese features carry no predictive signal and should be manually investigated.\n",
            "\t\tThis is typically a feature which has the same value for all rows.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\tUnused Original Features (Count: 42): ['nBondsA', 'NsF', 'NsCl', 'NsBr', 'NsI', 'SssssN', 'n11HRing', 'nG12HRing', 'n7aRing', 'n3ARing', 'n4ARing', 'n7ARing', 'n8ARing', 'n11ARing', 'nG12ARing', 'n3AHRing', 'n4AHRing', 'n7AHRing', 'n11AHRing', 'nG12AHRing', 'n6FHRing', 'n11FHRing', 'n8FaHRing', 'n9FaHRing', 'n12FaHRing', 'nG12FaHRing', 'n6FARing', 'n7FARing', 'n11FARing', 'n6FAHRing', 'n7FAHRing', 'n11FAHRing', 'MWC01', 'bit_153', 'bit_1515', 'num_of_atoms', 'num_of_heavy_atoms', 'num_heteroatoms', 'num_of_C_atoms', 'num_of_O_atoms', 'num_of_N_atoms', 'num_of_Cl_atoms']\n",
            "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
            "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\t\t('float', []) :  2 | ['SssssN', 'MWC01']\n",
            "\t\t('int', [])   : 40 | ['nBondsA', 'NsF', 'NsCl', 'NsBr', 'NsI', ...]\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('bool', [])  :    2 | ['Lipinski', 'GhoseFilter']\n",
            "\t\t('float', []) :  932 | ['AlogP', 'Molecular_Weight', 'LogD', 'Molecular_PolarSurfaceArea', 'SpAbs_A', ...]\n",
            "\t\t('int', [])   : 2199 | ['Num_H_Acceptors', 'Num_H_Donors', 'Num_RotatableBonds', 'nAcid', 'nBase', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     :  932 | ['AlogP', 'Molecular_Weight', 'LogD', 'Molecular_PolarSurfaceArea', 'SpAbs_A', ...]\n",
            "\t\t('int', [])       :  128 | ['Num_H_Acceptors', 'Num_H_Donors', 'Num_RotatableBonds', 'nAcid', 'nBase', ...]\n",
            "\t\t('int', ['bool']) : 2073 | ['NddsN', 'NssssN', 'NdS', 'NdssS', 'NaaSe', ...]\n",
            "\t14.3s = Fit runtime\n",
            "\t3133 features in original data used to generate 3133 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 36.63 MB (0.2% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 14.74s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
            "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': {},\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
            "\t'CAT': {},\n",
            "\t'XGB': {},\n",
            "\t'FASTAI': {},\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
            "}\n",
            "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
            "Fitting 11 L1 models ...\n",
            "Fitting model: KNeighborsUnif_BAG_L1 ...\n",
            "\t-36.897\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.38s\t = Training   runtime\n",
            "\t0.31s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist_BAG_L1 ...\n",
            "\t-36.827\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.38s\t = Training   runtime\n",
            "\t0.18s\t = Validation runtime\n",
            "Fitting model: LightGBMXT_BAG_L1 ...\n",
            "\tWarning: Exception caused LightGBMXT_BAG_L1 to fail during training... Skipping this model.\n",
            "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\Ag\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1733, in _train_and_save\n",
            "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\Ag\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1684, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\Ag\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\Ag\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 169, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\Ag\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 266, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\Ag\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 571, in _fit_folds\n",
            "    fold_fitting_strategy: FoldFittingStrategy = fold_fitting_strategy_cls(**fold_fitting_strategy_args)\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\Ag\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 476, in __init__\n",
            "    self.resources, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\Ag\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 684, in _get_resource_suggestions\n",
            "    resources_info = resources_calculator.get_resources_per_job(**get_resources_per_job_args)\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\Ag\\lib\\site-packages\\autogluon\\core\\ray\\resources_calculator.py\", line 56, in get_resources_per_job\n",
            "    assert cpu_per_job >= minimum_cpu_per_job, f\"The model requires minimum cpu {minimum_cpu_per_job}, but you only specified {cpu_per_job}\"\n",
            "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
            "Fitting model: LightGBM_BAG_L1 ...\n",
            "\tWarning: Exception caused LightGBM_BAG_L1 to fail during training... Skipping this model.\n",
            "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\Ag\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1733, in _train_and_save\n",
            "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\Ag\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1684, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\Ag\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\Ag\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 169, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\Ag\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 266, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\Ag\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 571, in _fit_folds\n",
            "    fold_fitting_strategy: FoldFittingStrategy = fold_fitting_strategy_cls(**fold_fitting_strategy_args)\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\Ag\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 476, in __init__\n",
            "    self.resources, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\Ag\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 684, in _get_resource_suggestions\n",
            "    resources_info = resources_calculator.get_resources_per_job(**get_resources_per_job_args)\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\Ag\\lib\\site-packages\\autogluon\\core\\ray\\resources_calculator.py\", line 56, in get_resources_per_job\n",
            "    assert cpu_per_job >= minimum_cpu_per_job, f\"The model requires minimum cpu {minimum_cpu_per_job}, but you only specified {cpu_per_job}\"\n",
            "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
            "Fitting model: RandomForestMSE_BAG_L1 ...\n",
            "\t-30.7028\t = Validation score   (-root_mean_squared_error)\n",
            "\t300.44s\t = Training   runtime\n",
            "\t5.29s\t = Validation runtime\n",
            "Fitting model: CatBoost_BAG_L1 ...\n",
            "\tWarning: Exception caused CatBoost_BAG_L1 to fail during training... Skipping this model.\n",
            "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\Ag\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1733, in _train_and_save\n",
            "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\Ag\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1684, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\Ag\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\Ag\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 169, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\Ag\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 266, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\Ag\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 571, in _fit_folds\n",
            "    fold_fitting_strategy: FoldFittingStrategy = fold_fitting_strategy_cls(**fold_fitting_strategy_args)\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\Ag\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 476, in __init__\n",
            "    self.resources, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\Ag\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 684, in _get_resource_suggestions\n",
            "    resources_info = resources_calculator.get_resources_per_job(**get_resources_per_job_args)\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\Ag\\lib\\site-packages\\autogluon\\core\\ray\\resources_calculator.py\", line 56, in get_resources_per_job\n",
            "    assert cpu_per_job >= minimum_cpu_per_job, f\"The model requires minimum cpu {minimum_cpu_per_job}, but you only specified {cpu_per_job}\"\n",
            "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
            "Fitting model: ExtraTreesMSE_BAG_L1 ...\n",
            "\t-30.2621\t = Validation score   (-root_mean_squared_error)\n",
            "\t100.9s\t = Training   runtime\n",
            "\t5.79s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI_BAG_L1 ...\n",
            "\tWarning: Exception caused NeuralNetFastAI_BAG_L1 to fail during training... Skipping this model.\n",
            "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\Ag\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1733, in _train_and_save\n",
            "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\Ag\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1684, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\Ag\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\Ag\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 169, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\Ag\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 266, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\Ag\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 571, in _fit_folds\n",
            "    fold_fitting_strategy: FoldFittingStrategy = fold_fitting_strategy_cls(**fold_fitting_strategy_args)\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\Ag\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 476, in __init__\n",
            "    self.resources, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\Ag\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 684, in _get_resource_suggestions\n",
            "    resources_info = resources_calculator.get_resources_per_job(**get_resources_per_job_args)\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\Ag\\lib\\site-packages\\autogluon\\core\\ray\\resources_calculator.py\", line 56, in get_resources_per_job\n",
            "    assert cpu_per_job >= minimum_cpu_per_job, f\"The model requires minimum cpu {minimum_cpu_per_job}, but you only specified {cpu_per_job}\"\n",
            "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
            "Fitting model: XGBoost_BAG_L1 ...\n",
            "\tWarning: Exception caused XGBoost_BAG_L1 to fail during training... Skipping this model.\n",
            "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\Ag\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1733, in _train_and_save\n",
            "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\Ag\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1684, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\Ag\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\Ag\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 169, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\Ag\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 266, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\Ag\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 571, in _fit_folds\n",
            "    fold_fitting_strategy: FoldFittingStrategy = fold_fitting_strategy_cls(**fold_fitting_strategy_args)\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\Ag\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 476, in __init__\n",
            "    self.resources, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\Ag\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 684, in _get_resource_suggestions\n",
            "    resources_info = resources_calculator.get_resources_per_job(**get_resources_per_job_args)\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\Ag\\lib\\site-packages\\autogluon\\core\\ray\\resources_calculator.py\", line 56, in get_resources_per_job\n",
            "    assert cpu_per_job >= minimum_cpu_per_job, f\"The model requires minimum cpu {minimum_cpu_per_job}, but you only specified {cpu_per_job}\"\n",
            "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
            "Fitting model: NeuralNetTorch_BAG_L1 ...\n",
            "\tWarning: Exception caused NeuralNetTorch_BAG_L1 to fail during training... Skipping this model.\n",
            "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\Ag\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1733, in _train_and_save\n",
            "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\Ag\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1684, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\Ag\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\Ag\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 169, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\Ag\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 266, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\Ag\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 571, in _fit_folds\n",
            "    fold_fitting_strategy: FoldFittingStrategy = fold_fitting_strategy_cls(**fold_fitting_strategy_args)\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\Ag\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 476, in __init__\n",
            "    self.resources, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\Ag\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 684, in _get_resource_suggestions\n",
            "    resources_info = resources_calculator.get_resources_per_job(**get_resources_per_job_args)\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\Ag\\lib\\site-packages\\autogluon\\core\\ray\\resources_calculator.py\", line 56, in get_resources_per_job\n",
            "    assert cpu_per_job >= minimum_cpu_per_job, f\"The model requires minimum cpu {minimum_cpu_per_job}, but you only specified {cpu_per_job}\"\n",
            "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
            "Fitting model: LightGBMLarge_BAG_L1 ...\n",
            "\tWarning: Exception caused LightGBMLarge_BAG_L1 to fail during training... Skipping this model.\n",
            "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\Ag\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1733, in _train_and_save\n",
            "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\Ag\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1684, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\Ag\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\Ag\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 169, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\Ag\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 266, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\Ag\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 571, in _fit_folds\n",
            "    fold_fitting_strategy: FoldFittingStrategy = fold_fitting_strategy_cls(**fold_fitting_strategy_args)\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\Ag\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 476, in __init__\n",
            "    self.resources, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\Ag\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 684, in _get_resource_suggestions\n",
            "    resources_info = resources_calculator.get_resources_per_job(**get_resources_per_job_args)\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\Ag\\lib\\site-packages\\autogluon\\core\\ray\\resources_calculator.py\", line 56, in get_resources_per_job\n",
            "    assert cpu_per_job >= minimum_cpu_per_job, f\"The model requires minimum cpu {minimum_cpu_per_job}, but you only specified {cpu_per_job}\"\n",
            "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t-30.2524\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.1s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting 9 L2 models ...\n",
            "Fitting model: LightGBMXT_BAG_L2 ...\n",
            "\tWarning: Exception caused LightGBMXT_BAG_L2 to fail during training... Skipping this model.\n",
            "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\Ag\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1733, in _train_and_save\n",
            "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\Ag\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1684, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\Ag\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\Ag\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 169, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\Ag\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 266, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\Ag\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 571, in _fit_folds\n",
            "    fold_fitting_strategy: FoldFittingStrategy = fold_fitting_strategy_cls(**fold_fitting_strategy_args)\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\Ag\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 476, in __init__\n",
            "    self.resources, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\Ag\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 684, in _get_resource_suggestions\n",
            "    resources_info = resources_calculator.get_resources_per_job(**get_resources_per_job_args)\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\Ag\\lib\\site-packages\\autogluon\\core\\ray\\resources_calculator.py\", line 56, in get_resources_per_job\n",
            "    assert cpu_per_job >= minimum_cpu_per_job, f\"The model requires minimum cpu {minimum_cpu_per_job}, but you only specified {cpu_per_job}\"\n",
            "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
            "Fitting model: LightGBM_BAG_L2 ...\n",
            "\tWarning: Exception caused LightGBM_BAG_L2 to fail during training... Skipping this model.\n",
            "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\Ag\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1733, in _train_and_save\n",
            "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\Ag\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1684, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\Ag\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 829, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\Ag\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 169, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\Ag\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 266, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\Ag\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 571, in _fit_folds\n",
            "    fold_fitting_strategy: FoldFittingStrategy = fold_fitting_strategy_cls(**fold_fitting_strategy_args)\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\Ag\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 476, in __init__\n",
            "    self.resources, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\Ag\\lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 684, in _get_resource_suggestions\n",
            "    resources_info = resources_calculator.get_resources_per_job(**get_resources_per_job_args)\n",
            "  File \"c:\\Users\\ineeji\\anaconda3\\envs\\Ag\\lib\\site-packages\\autogluon\\core\\ray\\resources_calculator.py\", line 56, in get_resources_per_job\n",
            "    assert cpu_per_job >= minimum_cpu_per_job, f\"The model requires minimum cpu {minimum_cpu_per_job}, but you only specified {cpu_per_job}\"\n",
            "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
            "Fitting model: RandomForestMSE_BAG_L2 ...\n"
          ]
        }
      ],
      "source": [
        "train_data = TabularDataset(train_mlm)\n",
        "test_data = TabularDataset(test)\n",
        "\n",
        "\n",
        "predictor = TabularPredictor(label='MLM',  eval_metric='rmse').fit(train_mlm, presets='best_quality',  ag_args_fit={'num_gpus': 0})\n",
        "predictor.leaderboard(train_mlm, silent=True)\n",
        "\n",
        "\n",
        "y_pred = predictor.predict(test_data)\n",
        "y_pred = pd.DataFrame(y_pred, columns=['MLM'])\n",
        "\n",
        "submission['MLM'] = y_pred['MLM']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictor.leaderboard(train_mlm, silent=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbpl6rSDxkqy",
        "outputId": "844737de-cbc5-4f65-c84e-08e0d54985cc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20230912_181511/\"\n",
            "Presets specified: ['high_quality']\n",
            "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
            "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (3471 samples, 92.06 MB).\n",
            "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20230912_181511/\"\n",
            "AutoGluon Version:  0.8.2\n",
            "Python Version:     3.10.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Fri Jun 9 10:57:30 UTC 2023\n",
            "Disk Space Avail:   143.37 GB / 179.07 GB (80.1%)\n",
            "Train Data Rows:    3471\n",
            "Train Data Columns: 3316\n",
            "Label Column: HLM\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
            "\tLabel info (max, min, mean, stddev): (135.336, 0.0, 53.17964, 36.03587)\n",
            "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    50038.14 MB\n",
            "\tTrain Data (Original)  Memory Usage: 92.03 MB (0.2% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 2097 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tUseless Original Features (Count: 139): ['nB', 'nP', 'NsLi', 'NssBe', 'NssssBe', 'NssBH', 'NsssB', 'NssssB', 'NtCH', 'NddC', 'NsNH3', 'NssNH2', 'NsssNH', 'NsSiH3', 'NssSiH2', 'NsssSiH', 'NssssSi', 'NsPH2', 'NssPH', 'NsssP', 'NdsssP', 'NsssssP', 'NsSH', 'NsGeH3', 'NssGeH2', 'NsssGeH', 'NssssGe', 'NsAsH2', 'NssAsH', 'NsssAs', 'NsssdAs', 'NsssssAs', 'NsSeH', 'NdSe', 'NssSe', 'NdssSe', 'NddssSe', 'NsSnH3', 'NssSnH2', 'NsssSnH', 'NssssSn', 'NsPbH3', 'NssPbH2', 'NsssPbH', 'NssssPb', 'SsLi', 'SssBe', 'SssssBe', 'SssBH', 'SsssB', 'SssssB', 'StCH', 'SddC', 'SsNH3', 'SssNH2', 'SsssNH', 'SsSiH3', 'SssSiH2', 'SsssSiH', 'SssssSi', 'SsPH2', 'SssPH', 'SsssP', 'SdsssP', 'SsssssP', 'SsSH', 'SsGeH3', 'SssGeH2', 'SsssGeH', 'SssssGe', 'SsAsH2', 'SssAsH', 'SsssAs', 'SsssdAs', 'SsssssAs', 'SsSeH', 'SdSe', 'SssSe', 'SdssSe', 'SddssSe', 'SsSnH3', 'SssSnH2', 'SsssSnH', 'SssssSn', 'SsPbH3', 'SssPbH2', 'SsssPbH', 'SssssPb', 'SMR_VSA8', 'SlogP_VSA9', 'n9Ring', 'n10Ring', 'n12Ring', 'n8HRing', 'n9HRing', 'n10HRing', 'n12HRing', 'n3aRing', 'n4aRing', 'n8aRing', 'n9aRing', 'n10aRing', 'n11aRing', 'n12aRing', 'nG12aRing', 'n3aHRing', 'n4aHRing', 'n7aHRing', 'n8aHRing', 'n9aHRing', 'n10aHRing', 'n11aHRing', 'n12aHRing', 'nG12aHRing', 'n9ARing', 'n10ARing', 'n12ARing', 'n8AHRing', 'n9AHRing', 'n10AHRing', 'n12AHRing', 'n4FRing', 'n5FRing', 'n4FHRing', 'n5FHRing', 'n4FaRing', 'n5FaRing', 'n6FaRing', 'n7FaRing', 'n11FaRing', 'n4FaHRing', 'n5FaHRing', 'n6FaHRing', 'n7FaHRing', 'n11FaHRing', 'n4FARing', 'n5FARing', 'n4FAHRing', 'n5FAHRing']\n",
            "\t\tThese features carry no predictive signal and should be manually investigated.\n",
            "\t\tThis is typically a feature which has the same value for all rows.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\tUnused Original Features (Count: 42): ['nBondsA', 'NsF', 'NsCl', 'NsBr', 'NsI', 'SssssN', 'n11HRing', 'nG12HRing', 'n7aRing', 'n3ARing', 'n4ARing', 'n7ARing', 'n8ARing', 'n11ARing', 'nG12ARing', 'n3AHRing', 'n4AHRing', 'n7AHRing', 'n11AHRing', 'nG12AHRing', 'n6FHRing', 'n11FHRing', 'n8FaHRing', 'n9FaHRing', 'n12FaHRing', 'nG12FaHRing', 'n6FARing', 'n7FARing', 'n11FARing', 'n6FAHRing', 'n7FAHRing', 'n11FAHRing', 'MWC01', 'bit_153', 'bit_1515', 'num_of_atoms', 'num_of_heavy_atoms', 'num_heteroatoms', 'num_of_C_atoms', 'num_of_O_atoms', 'num_of_N_atoms', 'num_of_Cl_atoms']\n",
            "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
            "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\t\t('float', []) :  2 | ['SssssN', 'MWC01']\n",
            "\t\t('int', [])   : 40 | ['nBondsA', 'NsF', 'NsCl', 'NsBr', 'NsI', ...]\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('bool', [])  :    2 | ['Lipinski', 'GhoseFilter']\n",
            "\t\t('float', []) :  934 | ['AlogP', 'Molecular_Weight', 'LogD', 'Molecular_PolarSurfaceArea', 'ABC', ...]\n",
            "\t\t('int', [])   : 2199 | ['Num_H_Acceptors', 'Num_H_Donors', 'Num_RotatableBonds', 'nAcid', 'nBase', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     :  934 | ['AlogP', 'Molecular_Weight', 'LogD', 'Molecular_PolarSurfaceArea', 'ABC', ...]\n",
            "\t\t('int', [])       :  128 | ['Num_H_Acceptors', 'Num_H_Donors', 'Num_RotatableBonds', 'nAcid', 'nBase', ...]\n",
            "\t\t('int', ['bool']) : 2073 | ['NddsN', 'NssssN', 'NdS', 'NdssS', 'NaaSe', ...]\n",
            "\t21.9s = Fit runtime\n",
            "\t3135 features in original data used to generate 3135 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 36.69 MB (0.1% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 22.35s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
            "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': {},\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
            "\t'CAT': {},\n",
            "\t'XGB': {},\n",
            "\t'FASTAI': {},\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
            "}\n",
            "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
            "Fitting 11 L1 models ...\n",
            "Fitting model: KNeighborsUnif_BAG_L1 ...\n",
            "\t-37.2175\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.54s\t = Training   runtime\n",
            "\t0.24s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist_BAG_L1 ...\n",
            "\t-37.1151\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.51s\t = Training   runtime\n",
            "\t0.24s\t = Validation runtime\n",
            "Fitting model: LightGBMXT_BAG_L1 ...\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "\t-31.1981\t = Validation score   (-root_mean_squared_error)\n",
            "\t279.71s\t = Training   runtime\n",
            "\t0.25s\t = Validation runtime\n",
            "Fitting model: LightGBM_BAG_L1 ...\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "\t-31.3695\t = Validation score   (-root_mean_squared_error)\n",
            "\t377.55s\t = Training   runtime\n",
            "\t0.23s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE_BAG_L1 ...\n",
            "\t-31.6304\t = Validation score   (-root_mean_squared_error)\n",
            "\t224.67s\t = Training   runtime\n",
            "\t4.09s\t = Validation runtime\n",
            "Fitting model: CatBoost_BAG_L1 ...\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "\t-31.4846\t = Validation score   (-root_mean_squared_error)\n",
            "\t146.91s\t = Training   runtime\n",
            "\t0.54s\t = Validation runtime\n",
            "Fitting model: ExtraTreesMSE_BAG_L1 ...\n",
            "\t-31.2275\t = Validation score   (-root_mean_squared_error)\n",
            "\t84.17s\t = Training   runtime\n",
            "\t3.9s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI_BAG_L1 ...\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "\t-33.0072\t = Validation score   (-root_mean_squared_error)\n",
            "\t100.26s\t = Training   runtime\n",
            "\t0.31s\t = Validation runtime\n",
            "Fitting model: XGBoost_BAG_L1 ...\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "\t-31.7984\t = Validation score   (-root_mean_squared_error)\n",
            "\t101.37s\t = Training   runtime\n",
            "\t0.37s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch_BAG_L1 ...\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "\t-33.1614\t = Validation score   (-root_mean_squared_error)\n",
            "\t159.86s\t = Training   runtime\n",
            "\t3.5s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge_BAG_L1 ...\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "\t-31.707\t = Validation score   (-root_mean_squared_error)\n",
            "\t2183.01s\t = Training   runtime\n",
            "\t0.44s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t-30.8953\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.55s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting 9 L2 models ...\n",
            "Fitting model: LightGBMXT_BAG_L2 ...\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "\t-31.3579\t = Validation score   (-root_mean_squared_error)\n",
            "\t228.64s\t = Training   runtime\n",
            "\t0.22s\t = Validation runtime\n",
            "Fitting model: LightGBM_BAG_L2 ...\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "\t-31.6619\t = Validation score   (-root_mean_squared_error)\n",
            "\t328.28s\t = Training   runtime\n",
            "\t0.21s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE_BAG_L2 ...\n",
            "\t-31.5465\t = Validation score   (-root_mean_squared_error)\n",
            "\t237.1s\t = Training   runtime\n",
            "\t3.86s\t = Validation runtime\n",
            "Fitting model: CatBoost_BAG_L2 ...\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "\t-31.1385\t = Validation score   (-root_mean_squared_error)\n",
            "\t77.47s\t = Training   runtime\n",
            "\t0.54s\t = Validation runtime\n",
            "Fitting model: ExtraTreesMSE_BAG_L2 ...\n",
            "\t-31.2973\t = Validation score   (-root_mean_squared_error)\n",
            "\t93.61s\t = Training   runtime\n",
            "\t4.23s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI_BAG_L2 ...\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "\t-32.942\t = Validation score   (-root_mean_squared_error)\n",
            "\t100.52s\t = Training   runtime\n",
            "\t0.31s\t = Validation runtime\n",
            "Fitting model: XGBoost_BAG_L2 ...\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "\t-31.7341\t = Validation score   (-root_mean_squared_error)\n",
            "\t96.58s\t = Training   runtime\n",
            "\t0.36s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch_BAG_L2 ...\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "\t-32.4623\t = Validation score   (-root_mean_squared_error)\n",
            "\t159.34s\t = Training   runtime\n",
            "\t3.48s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge_BAG_L2 ...\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
            "\t-31.9661\t = Validation score   (-root_mean_squared_error)\n",
            "\t1524.86s\t = Training   runtime\n",
            "\t0.25s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L3 ...\n",
            "\t-30.908\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.42s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 6601.54s ... Best model: \"WeightedEnsemble_L2\"\n",
            "Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
            "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
            "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
            "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
            "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
            "Fitting model: KNeighborsUnif_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
            "\t0.54s\t = Training   runtime\n",
            "\t0.24s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
            "\t0.51s\t = Training   runtime\n",
            "\t0.24s\t = Validation runtime\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
            "\t8.4s\t = Training   runtime\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: LightGBM_BAG_L1_FULL ...\n",
            "\t8.37s\t = Training   runtime\n",
            "Fitting model: RandomForestMSE_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
            "\t224.67s\t = Training   runtime\n",
            "\t4.09s\t = Validation runtime\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: CatBoost_BAG_L1_FULL ...\n",
            "\t23.34s\t = Training   runtime\n",
            "Fitting model: ExtraTreesMSE_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
            "\t84.17s\t = Training   runtime\n",
            "\t3.9s\t = Validation runtime\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: NeuralNetFastAI_BAG_L1_FULL ...\n",
            "\tStopping at the best epoch learned earlier - 1.\n",
            "\t3.5s\t = Training   runtime\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: XGBoost_BAG_L1_FULL ...\n",
            "\t10.97s\t = Training   runtime\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: NeuralNetTorch_BAG_L1_FULL ...\n",
            "\t12.37s\t = Training   runtime\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: LightGBMLarge_BAG_L1_FULL ...\n",
            "\t69.72s\t = Training   runtime\n",
            "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
            "\t0.55s\t = Training   runtime\n",
            "Fitting 1 L2 models ...\n",
            "Fitting model: LightGBMXT_BAG_L2_FULL ...\n",
            "\t3.41s\t = Training   runtime\n",
            "Fitting 1 L2 models ...\n",
            "Fitting model: LightGBM_BAG_L2_FULL ...\n",
            "\t4.4s\t = Training   runtime\n",
            "Fitting model: RandomForestMSE_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
            "\t237.1s\t = Training   runtime\n",
            "\t3.86s\t = Validation runtime\n",
            "Fitting 1 L2 models ...\n",
            "Fitting model: CatBoost_BAG_L2_FULL ...\n",
            "\t8.91s\t = Training   runtime\n",
            "Fitting model: ExtraTreesMSE_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
            "\t93.61s\t = Training   runtime\n",
            "\t4.23s\t = Validation runtime\n",
            "Fitting 1 L2 models ...\n",
            "Fitting model: NeuralNetFastAI_BAG_L2_FULL ...\n",
            "\tStopping at the best epoch learned earlier - 2.\n",
            "\t3.62s\t = Training   runtime\n",
            "Fitting 1 L2 models ...\n",
            "Fitting model: XGBoost_BAG_L2_FULL ...\n",
            "\t7.75s\t = Training   runtime\n",
            "Fitting 1 L2 models ...\n",
            "Fitting model: NeuralNetTorch_BAG_L2_FULL ...\n",
            "\t12.49s\t = Training   runtime\n",
            "Fitting 1 L2 models ...\n",
            "Fitting model: LightGBMLarge_BAG_L2_FULL ...\n",
            "\t30.26s\t = Training   runtime\n",
            "Fitting model: WeightedEnsemble_L3_FULL | Skipping fit via cloning parent ...\n",
            "\t0.42s\t = Training   runtime\n",
            "Refit complete, total runtime = 226.04s\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230912_181511/\")\n"
          ]
        }
      ],
      "source": [
        "train_data = TabularDataset(train_hlm)\n",
        "test_data = TabularDataset(test)\n",
        "\n",
        "\n",
        "predictor = TabularPredictor(label='HLM',  eval_metric='rmse').fit(train_hlm, presets='best_quality',  ag_args_fit={'num_gpus': 0})\n",
        "predictor.leaderboard(train_hlm, silent=True)\n",
        "\n",
        "\n",
        "y_pred = predictor.predict(test_data)\n",
        "y_pred = pd.DataFrame(y_pred, columns=['HLM'])\n",
        "\n",
        "submission['HLM'] = y_pred['HLM']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictor.leaderboard(train_hlm, silent=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P3oVH9QIxrAc"
      },
      "outputs": [],
      "source": [
        "submission.to_csv('best_qual.csv', index = False, encoding = \"utf-8-sig\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bHexh3orVzUq"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
